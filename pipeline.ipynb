{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \n",
    "api_user_auth = \n",
    "api_pass_auth = \n",
    "portofolio_label = \n",
    "start_period='2016-06-01'\n",
    "end_period='2020-09-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DolphinApi:\n",
    "    def __init__(self):\n",
    "        self.url = api_url\n",
    "        self.auth = (api_user_auth, api_pass_auth)\n",
    "        self.portofolio_label = portofolio_label\n",
    "        try:\n",
    "            self.currency_table = pd.read_csv(\"currency_table.csv\", index_col=0)\n",
    "        except FileNotFoundError: \n",
    "            self.currency_table = self.__get_currency_rate__()\n",
    "            self.currency_table.to_csv(\"currency_table.csv\")\n",
    "        try:\n",
    "            self.operations_table = pd.read_csv(\"operations_table.csv\", index_col=0)\n",
    "        except FileNotFoundError: \n",
    "            self.operations_table = self.__get_operations_table__()\n",
    "            self.operations_table.to_csv(\"operations_table.csv\")\n",
    "\n",
    "    def get(self, endpointApi, date=None, full_response=False):\n",
    "        payload = {'date': date, 'fullResponse': full_response}\n",
    "        res = requests.get(self.url + endpointApi,\n",
    "                           params=payload,\n",
    "                           auth=self.auth)\n",
    "        return res.content.decode('utf-8')\n",
    "\n",
    "    def put(self, endpointApi, content):\n",
    "        res = requests.put(url=self.url + endpointApi,\n",
    "                          data=json.dumps(content),\n",
    "                          auth=self.auth,\n",
    "                          headers = {\"content-type\": \"application/json\"})\n",
    "        return res.content.decode('utf-8')\n",
    "\n",
    "    def post(self, endpointApi, content):\n",
    "        res = requests.post(url=self.url + endpointApi,\n",
    "                    data=json.dumps(content),\n",
    "                    auth=self.auth,\n",
    "                    headers = {\"content-type\": \"application/json\"})\n",
    "        return res.content.decode('utf-8')\n",
    "\n",
    "    def __get_currency_rate__(self):\n",
    "        d = []\n",
    "        arr = json.loads(self.get('currency'))\n",
    "        for currency in arr:\n",
    "            currency_id = currency.get('id')\n",
    "            rate = self.get('currency/rate/{}/to/EUR'.format(currency_id))\n",
    "            if len(rate) != 0:\n",
    "                d.append([currency_id, (json.loads(rate)['rate']['value']).replace(',', '.')])\n",
    "        return pd.DataFrame(d, columns=['currency', 'rate'])\n",
    "\n",
    "    def __get_operations_table__(self):\n",
    "        data = self.get('ratio')\n",
    "        return pd.read_json(data)\n",
    "\n",
    "api = DolphinApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_eur(src_value):\n",
    "    value, src_currency = src_value.split(' ')\n",
    "    rate = api.currency_table[api.currency_table['currency']\n",
    "                              == src_currency]['rate'].values[0]\n",
    "    return float(value.replace(',', '.')) * float(rate)\n",
    "\n",
    "\n",
    "def convert_type(df):\n",
    "    for col in df.columns:\n",
    "        convert_values = []\n",
    "        for elt in df[col]:\n",
    "            if elt is np.nan:\n",
    "                convert_values.append(np.nan)\n",
    "                continue\n",
    "            elt_type = elt['type']\n",
    "            elt_value = elt['value']\n",
    "            if elt_type == 'currency_value':\n",
    "                elt_value = to_eur(elt_value)\n",
    "            elif elt_type == 'date':\n",
    "                elt_value = datetime.strptime(elt_value, '%Y-%m-%d').date()\n",
    "            elif elt_type in ['double', 'percent']:\n",
    "                elt_value = float(elt_value.replace(',', '.'))\n",
    "            elif elt_type in ['asset', 'int32', 'int64']:\n",
    "                elt_value = int(elt_value)\n",
    "            elif elt_type == 'boolean':\n",
    "                elt_value = json.loads(elt_value)\n",
    "            elif elt_type not in ['asset_type', 'string', 'asset_currency', 'date-time',\n",
    "                                  'asset_sub_type', 'asset_status', 'asset_quote_type',\n",
    "                                  'liquidity_algorithm', 'portfolio_lock_mode', 'portfolio_type']:\n",
    "                print(elt)\n",
    "            convert_values.append(elt_value)\n",
    "        df[col] = convert_values\n",
    "    return df\n",
    "\n",
    "\n",
    "def post_operations(ratios, ids, start, end, bench=None, frequency=None):\n",
    "    \"\"\"\n",
    "    Post request to the API\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ratios  : array\n",
    "        array of the operations to compute\n",
    "    ids     : array\n",
    "        array the assets IDs\n",
    "    start   : date\n",
    "        format: 'Y-m-d'\n",
    "    end     : date\n",
    "        format: 'Y-m-d'\n",
    "    Returns\n",
    "    -------\n",
    "        Dataframe of the response\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {'ratio': ratios,\n",
    "               'asset': ids,\n",
    "               'start_date': start,\n",
    "               'end_date': end,\n",
    "               'bench': bench,\n",
    "               'frequency': frequency}\n",
    "    data = api.post('ratio/invoke', payload)\n",
    "    data = pd.read_json(data)\n",
    "    operation = convert_type(data)\n",
    "    operation = operation.transpose()\n",
    "    operation.columns = np.array(\n",
    "        [api.operations_table[api.operations_table.id == i].name.values[0] for i in ratios])\n",
    "    return operation\n",
    "\n",
    "\n",
    "def get_portfolio(id_):\n",
    "    data = api.get('portfolio/{}/dyn_amount_compo'.format(id_))\n",
    "    portfolio = pd.read_json(data)\n",
    "    return portfolio\n",
    "\n",
    "\n",
    "def get_portfolio_IDs():\n",
    "    cols = [\"columns=TYPE\", \"columns=ASSET_DATABASE_ID\", \"columns=LABEL\"]\n",
    "    endpointApi = \"asset?{}&date={}\".format(\"&\".join(cols), start_period)\n",
    "    data = pd.read_json(api.get(endpointApi))\n",
    "    assets = convert_type(data)\n",
    "    assets = assets[(assets['TYPE'] == 'PORTFOLIO')].reset_index()\n",
    "    return assets\n",
    "    portfolio_id = assets.loc[\n",
    "        (assets['TYPE'] == 'PORTFOLIO') &\n",
    "        (assets['LABEL'] == api.portofolio_label)]['ASSET_DATABASE_ID'].values[0]\n",
    "    return int(portfolio_id)\n",
    "\n",
    "\n",
    "def get_epita_portfolio_id():\n",
    "    df_IDs = get_portfolio_IDs()\n",
    "    return int(df_IDs.loc[df_IDs['LABEL'] == 'EPITA_PTF_4']['ASSET_DATABASE_ID'])\n",
    "\n",
    "\n",
    "def get_epita_portfolio():\n",
    "    epita_portfolio_id = get_epita_portfolio_id()\n",
    "    return get_portfolio(epita_portfolio_id)\n",
    "\n",
    "\n",
    "def get_assets_portfolio(portfolio, date):\n",
    "    if date not in portfolio['values']:\n",
    "        return np.NaN\n",
    "    return portfolio['values'][date]\n",
    "\n",
    "\n",
    "def put_portfolio(portfolio_id, df_portfolio, assets):\n",
    "    label = df_portfolio['label'][0]\n",
    "    currency = df_portfolio['currency'][0]\n",
    "    type_ = df_portfolio['type'][0]\n",
    "    date = '2016-06-01'\n",
    "    form = '{{\"asset\":{{\"asset\": {}, \"quantity\": {}}}}},'\n",
    "    assets = ''.join([form.format(int(assets.iloc[i, 0]),\n",
    "                                  int(assets.iloc[i, 1]))\n",
    "                      for i in range(len(assets))])[:-1]\n",
    "    form = '{{\"label\": \"{}\", \"currency\": {{\"code\": \"{}\"}}, \"type\": \"{}\", \"values\": {{\"{}\": [{}]}}}}'\n",
    "    res = form.format(label, currency, type_, date, assets)\n",
    "    form = 'portfolio/{}/dyn_amount_compo'\n",
    "    api.put(form.format(portfolio_id), json.loads(res))\n",
    "\n",
    "\n",
    "def process_val(close, asset_currency, asset_min_buy, decimalisation):\n",
    "    return pow(10, -decimalisation) * (asset_min_buy or 1) * to_eur(str(close) + ' ' + asset_currency)\n",
    "\n",
    "\n",
    "def get_assets_ids(date):\n",
    "    cols = [\"columns=ASSET_DATABASE_ID\", \"columns=LABEL\",\n",
    "            \"columns=TYPE\", \"columns=LAST_CLOSE_VALUE_IN_CURR\",\n",
    "            \"columns=CURRENCY\", \"columns=MIN_BUY_AMOUNT\",\n",
    "            \"columns=asset_fund_info_decimalisation\"]\n",
    "    endpointApi = \"asset?{}&date={}\".format(\"&\".join(cols), date)\n",
    "    data = pd.read_json(api.get(endpointApi))\n",
    "    assets = convert_type(data)\n",
    "    assets = assets[(assets['LAST_CLOSE_VALUE_IN_CURR'].notna())\n",
    "                    & (assets['TYPE'] != 'PORTFOLIO')].reset_index()\n",
    "    assets['MIN_BUY_AMOUNT'] = assets['MIN_BUY_AMOUNT'].fillna(value=1)\n",
    "    assets['asset_fund_info_decimalisation'] = assets['asset_fund_info_decimalisation'].fillna(\n",
    "        value=0)\n",
    "    return assets[['ASSET_DATABASE_ID', 'CURRENCY', 'MIN_BUY_AMOUNT', 'asset_fund_info_decimalisation', \"TYPE\", \"LAST_CLOSE_VALUE_IN_CURR\"]]\n",
    "\n",
    "\n",
    "def get_type_table():\n",
    "    try:\n",
    "        type_table = pd.read_csv(\"type_table.csv\", index_col=0)\n",
    "        return type_table\n",
    "    except FileNotFoundError:\n",
    "        type_table = get_assets_ids(start_period)\n",
    "        type_table[[\"ASSET_DATABASE_ID\", \"TYPE\"]].to_csv(\"type_table.csv\")\n",
    "        return type_table[[\"ASSET_DATABASE_ID\", \"TYPE\"]]\n",
    "\n",
    "\n",
    "def get_type(id_):\n",
    "    type_table = get_type_table()\n",
    "    return type_table[type_table['ASSET_DATABASE_ID'] == id_].values[0, 0]\n",
    "\n",
    "\n",
    "def get_price_table():\n",
    "    price_table = get_quote_matrixes(start_period, end_period)[0].iloc[0, :]\n",
    "    return price_table\n",
    "\n",
    "\n",
    "def get_price(id_):\n",
    "    price_table = get_price_table()\n",
    "    return price_table[str(id_)].tolist()\n",
    "\n",
    "\n",
    "def get_quote_matrixes(start, end):\n",
    "    try:\n",
    "        all_closes = pd.read_csv(\"all_closes.csv\", index_col=0)\n",
    "        all_returns = pd.read_csv(\"all_returns.csv\", index_col=0)\n",
    "        return (all_closes, all_returns)\n",
    "    except FileNotFoundError:\n",
    "        assets = get_assets_ids(start)\n",
    "        cur = assets.values[0]\n",
    "        all_assets = get_quote(cur[0], start, end)\n",
    "        close_matrix = all_assets[['close']].set_index(all_assets.date)\n",
    "        close_matrix['close'] = close_matrix['close'].apply(\n",
    "            lambda x: process_val(x, cur[1], cur[2], cur[3]))\n",
    "        close_matrix.columns = ['{}'.format(cur[0])]\n",
    "        return_matrix = all_assets[['return']].set_index(all_assets.date)\n",
    "        return_matrix.columns = ['{}'.format(cur[0])]\n",
    "        for i in range(1, len(assets)):\n",
    "            cur = assets.values[i]\n",
    "            all_assets = get_quote(cur[0], start, end)\n",
    "            if 'close' in all_assets:\n",
    "                cur_close = all_assets[['close']].set_index(all_assets.date)\n",
    "                cur_close['close'] = cur_close['close'].apply(\n",
    "                    lambda x: process_val(x, cur[1], cur[2], cur[3]))\n",
    "                cur_close.columns = ['{}'.format(cur[0])]\n",
    "                close_matrix = pd.concat(\n",
    "                    [close_matrix, cur_close], axis=1, sort=False)\n",
    "            if 'return' in all_assets:\n",
    "                cur_return = all_assets[['return']].set_index(all_assets.date)\n",
    "                cur_return.columns = ['{}'.format(cur[0])]\n",
    "                return_matrix = pd.concat(\n",
    "                    [return_matrix, cur_return], axis=1, sort=False)\n",
    "\n",
    "        all_closes = close_matrix.sort_index().fillna(method='pad')\n",
    "        all_returns = return_matrix.sort_index().fillna(method='pad')\n",
    "        all_closes.to_csv(\"all_closes.csv\")\n",
    "        all_returns.to_csv(\"all_returns.csv\")\n",
    "        return (all_closes, all_returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_type(type_list):\n",
    "    table_type = get_type_table()\n",
    "    table_type = table_type[table_type.TYPE.isin(type_list)].ASSET_DATABASE_ID\n",
    "    return table_type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyswarm import pso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_constraint(x, assets_ids):\n",
    "    complete_price = 0\n",
    "    stocks_price = 0\n",
    "    for i, id_ in enumerate(assets_ids):\n",
    "        cur_price = get_price(id_) * 10000 * x[i]\n",
    "        if(get_type(id_) == \"STOCK\"):\n",
    "            stocks_price += cur_price\n",
    "        complete_price += cur_price\n",
    "    return stocks_price / complete_price\n",
    "\n",
    "\n",
    "def together_opti(assets_ids, fast):\n",
    "    data = get_quote_matrixes(start_period, end_period)[\n",
    "        1].fillna(method='bfill')\n",
    "    stock_counter = 1\n",
    "    return_matrix = []\n",
    "    cov_input = []\n",
    "\n",
    "    for i in assets_ids:\n",
    "        avg_return = data[str(i)].values.mean()\n",
    "        return_matrix.append(avg_return)\n",
    "        cov_input.append(data[str(i)].tolist())\n",
    "\n",
    "    return_matrix = np.matrix(return_matrix)\n",
    "    cov_input = np.matrix(cov_input)\n",
    "    cov_matrix = np.cov(cov_input)\n",
    "\n",
    "    portefolio_id = get_epita_portfolio_id()\n",
    "    portefolio = get_epita_portfolio()\n",
    "    nb_assets = len(assets_ids)\n",
    "\n",
    "    lb = [0] * nb_assets\n",
    "    lb2 = [0.01] * nb_assets\n",
    "    ub = [0.1] * nb_assets\n",
    "\n",
    "    constraints = [lambda x, assets_ids, c, d: np.sum(x) - 1,\n",
    "                   lambda x, assets_ids, c, d: stock_constraint(x, assets_ids) - 0.51]\n",
    "\n",
    "    if(not fast):\n",
    "        xopt, fopt = pso(opti_min_func, lb2, ub, ieqcons=constraints, args=(\n",
    "            assets_ids, return_matrix, cov_matrix), debug=True, swarmsize=1000, maxiter=30)\n",
    "    else:\n",
    "        xopt, fopt = pso(opti_min_func, lb, ub, ieqcons=[constraints[0]], args=(\n",
    "            assets_ids, return_matrix, cov_matrix), debug=False, swarmsize=100, maxiter=30, minstep=1e-4)\n",
    "\n",
    "    print(xopt)\n",
    "    optimal_sharpe_arr = xopt\n",
    "    return np.array(optimal_sharpe_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opti_min_func(weights, assets_id, return_matrix, cov_matrix):\n",
    "    \"\"\"\n",
    "    Function to calculate Sharpe ratio\n",
    "    \"\"\"\n",
    "    weights = [w / sum(weights) for w in weights]\n",
    "    weights = np.matrix(weights)\n",
    "    port_return = np.round(np.sum(weights * return_matrix.T) * 1274, 2)/5\n",
    "    port_volacity = np.round(\n",
    "        np.sqrt(weights * cov_matrix * weights.T) * np.sqrt(1274), 2)/np.sqrt(5)\n",
    "    sharpe_ratio = (port_return - 0.05) / float(port_volacity)\n",
    "    return sharpe_ratio\n",
    "\n",
    "def check_constraints(assets_ids, x):\n",
    "    print(\"stock part superior to 50%:\", stock_constraint(x, assets_ids) > 0.5)\n",
    "    print(\"%nav between 0.01 and 0.1:\", np.all(x < 0.1) and np.all(x > 0.01))\n",
    "    print(\"assets between 15 and 40:\", len(assets_ids) > 14 and len(assets_ids) < 41)\n",
    "\n",
    "\n",
    "def sharping_together():\n",
    "    stock_ids = select_type([\"STOCK\"])\n",
    "    fund_ids = select_type([\"ETF FUND\", \"FUND\", \"INDEX\"])\n",
    "    portefolio_id = get_epita_portfolio_id()\n",
    "    portefolio = get_epita_portfolio()\n",
    "\n",
    "    print(\"STOCKS\")\n",
    "    stock_part = together_opti(stock_ids, True)\n",
    "    df = pd.DataFrame(np.stack((stock_ids, stock_part), axis=-1),\n",
    "                      columns=[\"ids\", \"part\"]).sort_values(by=\"part\").values\n",
    "    stock_ids = df[:, 0][::-1][:40].astype(int)\n",
    "\n",
    "    print(\"NOT STOCKS\")\n",
    "    fund_part = together_opti(fund_ids, True)\n",
    "    df = pd.DataFrame(np.stack((fund_ids, fund_part), axis=-1),\n",
    "                      columns=[\"ids\", \"part\"]).sort_values(by=\"part\").values\n",
    "    fund_ids = df[:, 0][::-1][:40].astype(int)\n",
    "\n",
    "    print(\"REDUCE PART\")\n",
    "    reduced_ids = np.concatenate((stock_ids, fund_ids))\n",
    "    reduced_part = together_opti(reduced_ids, True)\n",
    "    df = pd.DataFrame(np.stack((reduced_ids, reduced_part), axis=-1),\n",
    "                      columns=[\"ids\", \"part\"]).sort_values(by=\"part\").values\n",
    "    final_ids = df[:, 0][::-1][:40].astype(int)\n",
    "\n",
    "    print(\"COMPUTE BEST\")\n",
    "    final_part = together_opti(final_ids, False)\n",
    "\n",
    "    check_constraints(final_ids, final_part)\n",
    "\n",
    "    assets_dataframe = pd.DataFrame(\n",
    "        data={'asset_id': final_ids, 'quantities': final_part * 1000000})\n",
    "\n",
    "    print(assets_dataframe)\n",
    "    put_portfolio(portefolio_id, portefolio, assets_dataframe)\n",
    "    post_operations([12], [portefolio_id], start_period,\n",
    "                    end_period).values[0, 0]\n",
    "    print(\"sharp of portfolio =\", post_operations(\n",
    "        [12], [portefolio_id], start_period, end_period).values[0, 0])\n",
    "\n",
    "    return final_part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharping_together()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}